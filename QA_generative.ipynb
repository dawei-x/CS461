{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAuNBkmI6Qj7",
        "outputId": "cba113b3-8862-4ff3-edc5-7122bdb1e74d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Files imported\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, BertModel, GPT2LMHeadModel, GPT2Tokenizer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cs461dir = '/content/drive/My Drive/Colab Notebooks/CS461/'\n",
        "\n",
        "file_paths = ['train_complete.jsonl', 'dev_complete.jsonl', 'test_complete.jsonl']\n",
        "if any(not os.path.exists(filepath) for filepath in file_paths):\n",
        "  !cp -r \"{cs461dir}\"* /content/\n",
        "  print(\"Files imported\")\n",
        "\n",
        "model_path = \"./model_weights\"\n",
        "os.makedirs(model_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCxDp3GX6X57"
      },
      "outputs": [],
      "source": [
        "def load_data_generative():\n",
        "  train = []\n",
        "  valid = []\n",
        "  test = []\n",
        "\n",
        "  file_name = 'train_complete.jsonl'\n",
        "  with open(file_name) as json_file:\n",
        "      json_list = list(json_file)\n",
        "  for i in range(len(json_list)):\n",
        "      json_str = json_list[i]\n",
        "      result = json.loads(json_str)\n",
        "\n",
        "      base = result[\"fact1\"] + \" \" + result[\"question\"][\"stem\"]\n",
        "      choices = result[\"question\"][\"choices\"]\n",
        "      ans = result[\"answerKey\"]\n",
        "\n",
        "      text = f'[START] {base} [A] {choices[0][\"text\"]} [B] {choices[1][\"text\"]} [C] {choices[2][\"text\"]} [D] {choices[3][\"text\"]} [ANSWER] {ans}'\n",
        "      train.append([text, ans])\n",
        "\n",
        "  file_name = 'dev_complete.jsonl'\n",
        "  with open(file_name) as json_file:\n",
        "      json_list = list(json_file)\n",
        "  for i in range(len(json_list)):\n",
        "      json_str = json_list[i]\n",
        "      result = json.loads(json_str)\n",
        "\n",
        "      base = result[\"fact1\"] + \" \" + result[\"question\"][\"stem\"]\n",
        "      choices = result[\"question\"][\"choices\"]\n",
        "      ans = result[\"answerKey\"]\n",
        "\n",
        "      text = f'[START] {base} [A] {choices[0][\"text\"]} [B] {choices[1][\"text\"]} [C] {choices[2][\"text\"]} [D] {choices[3][\"text\"]} [ANSWER] {ans}'\n",
        "      valid.append([text, ans])\n",
        "\n",
        "  file_name = 'test_complete.jsonl'\n",
        "  with open(file_name) as json_file:\n",
        "      json_list = list(json_file)\n",
        "  for i in range(len(json_list)):\n",
        "      json_str = json_list[i]\n",
        "      result = json.loads(json_str)\n",
        "\n",
        "      base = result[\"fact1\"] + \" \" + result[\"question\"][\"stem\"]\n",
        "      choices = result[\"question\"][\"choices\"]\n",
        "      ans = result[\"answerKey\"]\n",
        "\n",
        "      text = f'[START] {base} [A] {choices[0][\"text\"]} [B] {choices[1][\"text\"]} [C] {choices[2][\"text\"]} [D] {choices[3][\"text\"]} [ANSWER] {ans}'\n",
        "      test.append([text, ans])\n",
        "\n",
        "  return train, valid, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR3YaJvs6abh"
      },
      "outputs": [],
      "source": [
        "def train_model(model, opt):\n",
        "  print(\"training model...\")\n",
        "  model.to(opt.device)\n",
        "  model.train()\n",
        "\n",
        "  optimizer = opt.optimizer\n",
        "  data = opt.train\n",
        "\n",
        "  for epoch in range(opt.epochs):\n",
        "    total_loss = 0\n",
        "    random.shuffle(data)\n",
        "    for i in range(0, len(data), opt.batchsize):\n",
        "      batch = data[i: i + opt.batchsize]\n",
        "      inputs = []\n",
        "\n",
        "      for question, _ in batch:\n",
        "        input = opt.tokenizer(question, padding = 'max_length', truncation=True, max_length = opt.max_length)\n",
        "        inputs.append(torch.tensor(input[\"input_ids\"]).squeeze(0))\n",
        "\n",
        "      inputs = torch.stack(inputs).to(opt.device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(input_ids = inputs, labels = inputs)\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), opt.norm)\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / (len(data) / opt.batchsize)\n",
        "    print(f\"Epoch {epoch+1}/{opt.epochs}, Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE0JMoNB6gYZ"
      },
      "outputs": [],
      "source": [
        "def test(model, opt, test_dataset=\"valid\", verbose = False):\n",
        "  model.eval()\n",
        "  model.to(opt.device)\n",
        "\n",
        "  data = getattr(opt, test_dataset)\n",
        "\n",
        "  total_correct = 0\n",
        "  num_printed = 0\n",
        "  num_samples = len(data) - len(data) % opt.batchsize\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in range(0, num_samples, opt.batchsize):\n",
        "      batch = data[i: i + opt.batchsize]\n",
        "      prompts = []\n",
        "      labels = []\n",
        "      # remove answer\n",
        "      for question, answer in batch:\n",
        "        prompt = question.split(\"[ANSWER]\")[0] + \"[ANSWER]\"\n",
        "        prompts.append(prompt)\n",
        "        labels.append(answer)\n",
        "\n",
        "      inputs = opt.tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\").to(opt.device)\n",
        "\n",
        "      outputs = model.generate(input_ids = inputs[\"input_ids\"], max_new_tokens = opt.max_new_tokens, pad_token_id = opt.tokenizer.eos_token_id)\n",
        "      generated = opt.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "      generated = [gen_ans.split(\"[ANSWER]\")[1].strip()[0] if \"[ANSWER]\" in gen_ans else \"\" for gen_ans in generated]\n",
        "\n",
        "      for (question_input, true_answer, gen_answer) in zip(prompts, labels, generated):\n",
        "        # print examples\n",
        "        if verbose and num_printed < opt.num_examples:\n",
        "          print(\"\\n Example\", num_printed + 1)\n",
        "          print(f\" Question: {question_input}\")\n",
        "          print(f\" True Answer: {true_answer}\")\n",
        "          print(f\" Predicted Answer: {gen_answer}\")\n",
        "          num_printed += 1\n",
        "        if gen_answer == true_answer:\n",
        "          total_correct += 1\n",
        "\n",
        "  accuracy = total_correct / num_samples\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "5BhjFukb6jyk",
        "outputId": "72cd30cd-85cf-4228-a1e7-59a9b5a294f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "testing model pre-trained model...\n",
            "\n",
            "Zero-shot accuracy on validation dataset: 0.004\n",
            "Zero-shot accuracy on test dataset: 0.000\n",
            "Now fine-tuning...\n",
            "training model...\n",
            "Epoch 1/20, Loss: 1.0673\n",
            "Epoch 2/20, Loss: 0.8510\n",
            "Epoch 3/20, Loss: 0.7551\n",
            "Epoch 4/20, Loss: 0.6893\n",
            "Epoch 5/20, Loss: 0.6330\n",
            "Epoch 6/20, Loss: 0.5811\n",
            "Epoch 7/20, Loss: 0.5355\n",
            "Epoch 8/20, Loss: 0.4895\n",
            "Epoch 9/20, Loss: 0.4483\n",
            "Epoch 10/20, Loss: 0.4099\n",
            "Epoch 11/20, Loss: 0.3749\n",
            "Epoch 12/20, Loss: 0.3445\n",
            "Epoch 13/20, Loss: 0.3162\n",
            "Epoch 14/20, Loss: 0.2903\n",
            "Epoch 15/20, Loss: 0.2680\n",
            "Epoch 16/20, Loss: 0.2476\n",
            "Epoch 17/20, Loss: 0.2295\n",
            "Epoch 18/20, Loss: 0.2151\n",
            "Epoch 19/20, Loss: 0.2006\n",
            "Epoch 20/20, Loss: 0.1893\n",
            "testing model fine-tuned model...\n",
            "\n",
            "\n",
            " Example 1\n",
            " Question: [START] deep sea animals live deep in the ocean Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as [A] Deep sea animals [B] fish [C] Long Sea Fish [D] Far Sea Animals [ANSWER]\n",
            " True Answer: A\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 2\n",
            " Question: [START] Matter in the liquid phase has definite volume Gas can fill any container it is given, and liquid [A] is standard weight and size [B] is the opposite of variable [C] only needs a few [D] uses what it needs [ANSWER]\n",
            " True Answer: D\n",
            " Predicted Answer: B\n",
            "\n",
            " Example 3\n",
            " Question: [START] migration is an instinctive behavior When birds migrate south for the winter, they do it because [A] they are genetically called to [B] their children ask for them to [C] it is important to their happiness [D] they decide to each year [ANSWER]\n",
            " True Answer: A\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 4\n",
            " Question: [START] a compass is a kind of tool for determining direction by pointing north If a person walks in the opposite direction of a compass arrow they are walking [A] west [B] north [C] east [D] south [ANSWER]\n",
            " True Answer: D\n",
            " Predicted Answer: B\n",
            "\n",
            " Example 5\n",
            " Question: [START] as an object moves , the kinetic energy of that object will increase An example of lots kinetic energy would be [A] Drinking a cold glass of water [B] A snail moving across the sidewalk [C] sitting without moving anywhere [D] An aircraft taking a trip [ANSWER]\n",
            " True Answer: D\n",
            " Predicted Answer: C\n",
            "\n",
            " Example 6\n",
            " Question: [START] a single-cell organism cannot specialize Which organism cannot specialize? [A] mammal [B] plant [C] fish [D] protozoa [ANSWER]\n",
            " True Answer: D\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 7\n",
            " Question: [START] a greenhouse is used to protect plants from the cold A person can grow cabbage in January with the help of what product? [A] Green house [B] Parliment [C] Congress [D] White house [ANSWER]\n",
            " True Answer: A\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 8\n",
            " Question: [START] an amphibian is cold-blooded A frog, in winter, will burrow itself into soft mud, until it freezes, then in the spring [A] it melts, because it is warm-blooded [B] it unfreezes, because it is cold-blooded [C] it remains frozen until it dies [D] it dies, because it is warm-blooded [ANSWER]\n",
            " True Answer: B\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 1\n",
            " Question: [START] using less resources usually causes money to be saved A person wants to start saving money so that they can afford a nice vacation at the end of the year. After looking over their budget and expenses, they decide the best way to save money is to [A] make more phone calls [B] quit eating lunch out [C] buy less with monopoly money [D] have lunch with friends [ANSWER]\n",
            " True Answer: B\n",
            " Predicted Answer: C\n",
            "\n",
            " Example 2\n",
            " Question: [START] fog is formed by water vapor condensing in the air There is most likely going to be fog around: [A] a marsh [B] a tundra [C] the plains [D] a desert [ANSWER]\n",
            " True Answer: A\n",
            " Predicted Answer: C\n",
            "\n",
            " Example 3\n",
            " Question: [START] predators eat prey Predators eat [A] lions [B] humans [C] bunnies [D] grass [ANSWER]\n",
            " True Answer: C\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 4\n",
            " Question: [START] if a tree is located near a sidewalk then the roots of that tree might crack the sidewalk Oak tree seeds are planted and a sidewalk is paved right next to that spot, until eventually, the tree is tall and the roots must extend past the sidewalk, which means [A] roots may be split [B] roots may begin to die [C] parts may break the concrete [D] roots may fall apart [ANSWER]\n",
            " True Answer: C\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 5\n",
            " Question: [START] An electrical conductor is a vehicle for the flow of electricity An electric car runs on electricity via [A] gasoline [B] a power station [C] electrical conductors [D] fuel [ANSWER]\n",
            " True Answer: C\n",
            " Predicted Answer: C\n",
            "\n",
            " Example 6\n",
            " Question: [START] as the population of plants decreases , carbon in the atmosphere will increase As the rain forest is deforested the atmosphere will increase with [A] oxygen [B] nitrogen [C] carbon [D] rain [ANSWER]\n",
            " True Answer: C\n",
            " Predicted Answer: A\n",
            "\n",
            " Example 7\n",
            " Question: [START] an electric car contains an electric motor an electric car contains a motor that runs on [A] gas [B] hydrogen [C] ions [D] plutonium [ANSWER]\n",
            " True Answer: C\n",
            " Predicted Answer: C\n",
            "\n",
            " Example 8\n",
            " Question: [START] the sun is located directly overhead at noon The middle of the day usually involves the bright star nearest to the earth to be straight overhead why? [A] moons gravity [B] human planet rotation [C] global warming [D] moon rotation [ANSWER]\n",
            " True Answer: B\n",
            " Predicted Answer: C\n",
            "Fine-tuned accuracy on validation dataset: 0.377\n",
            "Fine-tuned accuracy on test dataset: 0.375\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "  random.seed(10)\n",
        "\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('-no_cuda', action='store_true')\n",
        "  parser.add_argument('-epochs', type=int, default=20)\n",
        "  parser.add_argument('-batchsize', type=int, default=8)\n",
        "  parser.add_argument('-lr', type=float, default=5e-5)\n",
        "  parser.add_argument('-norm', type=float, default=1.0)\n",
        "  parser.add_argument('-max_length', type=int, default=128)\n",
        "  parser.add_argument('-max_new_tokens', type=int, default=3)\n",
        "  parser.add_argument('-num_examples', type=int, default=8)\n",
        "\n",
        "  if \"google.colab\" in sys.modules:\n",
        "    sys.argv = [\"notebook\"]\n",
        "\n",
        "  opt = parser.parse_args()\n",
        "\n",
        "  opt.device = torch.device(\"cuda\" if torch.cuda.is_available() and not opt.no_cuda else \"cpu\")\n",
        "\n",
        "  model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "  opt.optimizer = optim.AdamW(model.parameters(), lr=opt.lr)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "  if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"left\"\n",
        "  opt.tokenizer = tokenizer\n",
        "\n",
        "  opt.train, opt.valid, opt.test = load_data_generative()\n",
        "\n",
        "  print(\"testing model pre-trained model...\\n\")\n",
        "\n",
        "  zeroshot_valid_acc = test(model, opt, test_dataset = \"valid\")\n",
        "  zeroshot_test_acc = test(model, opt, test_dataset = \"test\")\n",
        "  print(f\"Zero-shot accuracy on validation dataset: {zeroshot_valid_acc:.3f}\")\n",
        "  print(f\"Zero-shot accuracy on test dataset: {zeroshot_test_acc:.3f}\")\n",
        "\n",
        "  print(\"Now fine-tuning...\")\n",
        "\n",
        "  train_model(model, opt)\n",
        "\n",
        "  print(\"testing model fine-tuned model...\\n\")\n",
        "\n",
        "  finetuned_valid_acc = test(model, opt, test_dataset = \"valid\", verbose = True)\n",
        "  finetuned_test_acc = test(model, opt, test_dataset = \"test\", verbose = True)\n",
        "  print(f\"Fine-tuned accuracy on validation dataset: {finetuned_valid_acc:.3f}\")\n",
        "  print(f\"Fine-tuned accuracy on test dataset: {finetuned_test_acc:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}